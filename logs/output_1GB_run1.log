2025-05-08 16:46:03,613 - INFO - NVTabular version: 23.08.00
2025-05-08 16:46:03,614 - INFO - cuDF version: 23.04.01
2025-05-08 16:46:03,614 - INFO - Pandas version: 1.5.3
2025-05-08 16:46:03,616 - INFO - visible_devices: 0
2025-05-08 16:46:03,616 - INFO - Device size: 25.33 GB
2025-05-08 16:46:03,616 - INFO - Device limit: 17.73 GB
2025-05-08 16:46:03,616 - INFO - Device pool size: 20.26 GB
2025-05-08 16:46:05,701 - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy
2025-05-08 16:46:05,726 - INFO - State start
2025-05-08 16:46:05,733 - INFO -   Scheduler at:     tcp://127.0.0.1:39721
2025-05-08 16:46:05,733 - INFO -   dashboard at:  http://127.0.0.1:8787/status
2025-05-08 16:46:05,839 - INFO -         Start Nanny at: 'tcp://127.0.0.1:40741'
2025-05-08 16:46:11,727 - INFO - NVTabular version: 23.08.00
2025-05-08 16:46:11,728 - INFO - cuDF version: 23.04.01
2025-05-08 16:46:11,728 - INFO - Pandas version: 1.5.3
2025-05-08 16:46:11,732 - distributed.preloading - INFO - Creating preload: dask_cuda.initialize
2025-05-08 16:46:11,732 - INFO - Creating preload: dask_cuda.initialize
2025-05-08 16:46:11,732 - distributed.preloading - INFO - Import preload module: dask_cuda.initialize
2025-05-08 16:46:11,732 - INFO - Import preload module: dask_cuda.initialize
2025-05-08 16:46:11,773 - INFO - Run preload setup: dask_cuda.initialize
2025-05-08 16:46:12,074 - INFO -       Start worker at:      tcp://127.0.0.1:46375
2025-05-08 16:46:12,074 - INFO -          Listening to:      tcp://127.0.0.1:46375
2025-05-08 16:46:12,074 - INFO -           Worker name:                          0
2025-05-08 16:46:12,074 - INFO -          dashboard at:            127.0.0.1:34153
2025-05-08 16:46:12,074 - INFO - Waiting to connect to:      tcp://127.0.0.1:39721
2025-05-08 16:46:12,075 - INFO - -------------------------------------------------
2025-05-08 16:46:12,075 - INFO -               Threads:                          1
2025-05-08 16:46:12,075 - INFO -                Memory:                 251.74 GiB
2025-05-08 16:46:12,075 - INFO -       Local Directory: /tmp/dask-worker-space/worker-g_8b_fe2
2025-05-08 16:46:12,075 - INFO - Starting Worker plugin PreImport-cc594912-eb08-4f3a-bc03-7c87e21e37cf
2025-05-08 16:46:12,075 - INFO - Starting Worker plugin CPUAffinity-a40a85e5-b1b9-4589-aff7-ea1cf3afd4c1
2025-05-08 16:46:12,076 - INFO - Starting Worker plugin RMMSetup-0adc3910-101c-4927-890f-39eaa37d98c8
2025-05-08 16:46:19,745 - INFO - -------------------------------------------------
2025-05-08 16:46:19,888 - INFO - Register worker <WorkerState 'tcp://127.0.0.1:46375', name: 0, status: init, memory: 0, processing: 0>
2025-05-08 16:46:19,901 - INFO - Starting worker compute stream, tcp://127.0.0.1:46375
2025-05-08 16:46:19,901 - INFO - Starting established connection to tcp://127.0.0.1:56968
2025-05-08 16:46:19,901 - INFO -         Registered to:      tcp://127.0.0.1:39721
2025-05-08 16:46:19,901 - INFO - -------------------------------------------------
2025-05-08 16:46:19,904 - INFO - Starting established connection to tcp://127.0.0.1:39721
2025-05-08 16:46:19,912 - INFO - Receive client connection: Client-34255044-2c1b-11f0-af10-506b4bdbc6c4
2025-05-08 16:46:19,912 - INFO - Starting established connection to tcp://127.0.0.1:56974
2025-05-08 16:46:19,914 - INFO - Found 512 training files
2025-05-08 16:46:19,914 - INFO - First file: /local/home/yuzhuyu/criteo_1TB/criteo_1TB_part_0332.parquet
2025-05-08 16:46:19,914 - INFO - Last file: /local/home/yuzhuyu/criteo_1TB/criteo_1TB_part_0142.parquet
2025-05-08 16:46:19,916 - INFO - Total data size: 736.68 GB
2025-05-08 16:46:19,916 - INFO - Setting up workflow...
2025-05-08 16:46:19,917 - INFO - Creating dataset...
2025-05-08 16:46:21,167 - INFO - Dataset created successfully with cuDF engine
2025-05-08 16:46:21,168 - INFO - Part size: 1GB
2025-05-08 16:46:21,168 - INFO - Fitting workflow...
2025-05-08 16:46:21,168 - INFO - Initial GPU 0 memory usage: 20.96 GB
2025-05-08 16:46:21,718 - INFO - Run out-of-band function 'clean_worker_cache'
2025-05-08 16:52:22,760 - INFO - full garbage collection released 247.27 MiB from 406 reference cycles (threshold: 9.54 MiB)
2025-05-08 16:52:33,367 - INFO - Connection to tcp://127.0.0.1:56968 has been closed.
2025-05-08 16:52:33,369 - INFO - Remove worker <WorkerState 'tcp://127.0.0.1:46375', name: 0, status: running, memory: 234, processing: 2>
2025-05-08 16:52:33,370 - INFO - Removing comms to tcp://127.0.0.1:46375
2025-05-08 16:52:33,391 - INFO - Lost all workers
2025-05-08 16:52:40,425 - INFO - Worker process 2912480 was killed by signal 7
2025-05-08 16:52:40,430 - distributed.nanny - WARNING - Restarting worker
2025-05-08 16:52:40,430 - WARNING - Restarting worker
2025-05-08 16:52:48,394 - INFO - Closing Nanny at 'tcp://127.0.0.1:40741'. Reason: nanny-close
Traceback (most recent call last):
  File "<string>", line 1, in <module>
  File "/home/yuzhuyu/miniconda3/envs/nvtabular_23_08/lib/python3.10/multiprocessing/spawn.py", line 116, in spawn_main
  File "/home/yuzhuyu/miniconda3/envs/nvtabular_23_08/lib/python3.10/multiprocessing/spawn.py", line 125, in _main
  File "/home/yuzhuyu/miniconda3/envs/nvtabular_23_08/lib/python3.10/multiprocessing/spawn.py", line 236, in prepare
  File "/home/yuzhuyu/miniconda3/envs/nvtabular_23_08/lib/python3.10/multiprocessing/spawn.py", line 287, in _fixup_main_from_path
  File "/home/yuzhuyu/miniconda3/envs/nvtabular_23_08/lib/python3.10/runpy.py", line 289, in run_path
  File "/home/yuzhuyu/miniconda3/envs/nvtabular_23_08/lib/python3.10/runpy.py", line 96, in _run_module_code
  File "/home/yuzhuyu/miniconda3/envs/nvtabular_23_08/lib/python3.10/runpy.py", line 86, in _run_code
  File "/home/yuzhuyu/u55c/rec_preprocessing/nvtabular_gpu_1TB_8k_no_vocab_dask.py", line 17, in <module>
    import dask_cudf
  File "/home/yuzhuyu/miniconda3/envs/nvtabular_23_08/lib/python3.10/site-packages/dask_cudf/__init__.py", line 5, in <module>
  File "/home/yuzhuyu/miniconda3/envs/nvtabular_23_08/lib/python3.10/site-packages/cudf/__init__.py", line 10, in <module>
  File "/home/yuzhuyu/miniconda3/envs/nvtabular_23_08/lib/python3.10/site-packages/rmm/__init__.py", line 15, in <module>
  File "/home/yuzhuyu/miniconda3/envs/nvtabular_23_08/lib/python3.10/site-packages/rmm/mr.py", line 14, in <module>
  File "/home/yuzhuyu/miniconda3/envs/nvtabular_23_08/lib/python3.10/site-packages/rmm/_lib/__init__.py", line 15, in <module>
  File "device_buffer.pyx", line 1, in init rmm._lib.device_buffer
ModuleNotFoundError: No module named 'rmm._lib.memory_resource'
2025-05-08 16:53:02,924 - INFO - Worker process 2915144 was killed by signal 7
